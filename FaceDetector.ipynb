{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7864edba-33a3-498f-b13e-1140e26e294e",
   "metadata": {},
   "source": [
    "# Data Retrieval and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2509fc9-f089-4357-92d2-b06955129450",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7295a5-689b-40c9-8bea-82944c73b40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: labelme in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (5.2.1)\n",
      "Requirement already satisfied: tensorflow in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (2.13.0)\n",
      "Requirement already satisfied: opencv-python in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (4.8.0.74)\n",
      "Requirement already satisfied: matplotlib in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: albumentations in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (1.3.1)\n",
      "Requirement already satisfied: imgviz>=0.11 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from labelme) (1.7.3)\n",
      "Requirement already satisfied: PyYAML in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from labelme) (6.0)\n",
      "Requirement already satisfied: termcolor in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from labelme) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from labelme) (1.22.4)\n",
      "Requirement already satisfied: qtpy!=1.11.2 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from labelme) (2.0.1)\n",
      "Requirement already satisfied: Pillow>=2.8 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from labelme) (9.2.0)\n",
      "Requirement already satisfied: natsort>=7.1.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from labelme) (8.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.56.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: packaging in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (1.7.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (4.8.0.74)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from albumentations) (0.19.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.7.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2021.7.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/thomasjcarriero/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install labelme tensorflow opencv-python matplotlib albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818416e5-00da-4abb-9d69-3a7524126183",
   "metadata": {},
   "source": [
    "## Image Collection with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94da87c9-8114-42e5-b606-1241cfc69bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8571db31-6fe1-4503-a18a-91fae44b95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data', 'images')\n",
    "number_images = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37cd156-76a3-48c6-9a99-63df76694eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting image 5\n",
      "Collecting image 6\n",
      "Collecting image 7\n",
      "Collecting image 8\n",
      "Collecting image 9\n",
      "Collecting image 10\n",
      "Collecting image 11\n",
      "Collecting image 12\n",
      "Collecting image 13\n",
      "Collecting image 14\n",
      "Collecting image 15\n",
      "Collecting image 16\n",
      "Collecting image 17\n",
      "Collecting image 18\n",
      "Collecting image 19\n",
      "Collecting image 20\n",
      "Collecting image 21\n",
      "Collecting image 22\n",
      "Collecting image 23\n",
      "Collecting image 24\n",
      "Collecting image 25\n",
      "Collecting image 26\n",
      "Collecting image 27\n",
      "Collecting image 28\n",
      "Collecting image 29\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "for imgnum in range(number_images):\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(IMAGES_PATH, f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imgname, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5508c-ee83-46b4-91df-9ae0aa0e50f7",
   "metadata": {},
   "source": [
    "## Annotate Images with LabelMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04fbe703-a856-4579-ad34-ce9f878e2485",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190bd32-c749-4cba-bab3-edace6786869",
   "metadata": {},
   "source": [
    "# Review Dataset and Build Image Loading Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e846aa9-06f9-418d-83ea-60c9ed49f9c0",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d164d0e-4b13-4961-aeb0-441394dea8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8c631-3479-4fb4-a2a2-783957a3e2a0",
   "metadata": {},
   "source": [
    "## Limit GPU Memory Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092508c2-d72c-498c-8d8f-e5e2ed4820b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpus \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physcial_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gpu \u001b[38;5;129;01min\u001b[39;00m gpus:\n\u001b[1;32m      3\u001b[0m     tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mset_memory_growth(gpu, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physcial_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f9af4-cca8-4342-87ea-5b1763b7181c",
   "metadata": {},
   "source": [
    "## Load Image into TensorFlow Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cc60a-578f-4689-b50c-8fece4593fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.list_files('data\\\\images\\\\*.jpg', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39cc7bf-599d-4256-b9d2-8a5fbe97e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e6686-0399-4922-842a-2147d8a64667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5a337-0a5a-48c5-a044-aa63cef39d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6588f-381c-40bc-9f07-55d37705fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.as_numpy_iterator().next()\n",
    "# type(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c34d0d-b749-42ae-9449-fe8b6a524c3b",
   "metadata": {},
   "source": [
    "## View Raw Images with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f285ed-c9f0-489c-a261-65adc0dba1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = images.batch(4).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751c35a-ab5e-471a-aade-1f9a30a7ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images = image_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2590e54-b862-4112-baf2-71e7c44bf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, image in enumerate(plot_images):\n",
    "    ax[idx].imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b55939-9ccd-4883-a8eb-c4e9bdef50ca",
   "metadata": {},
   "source": [
    "# Partition Unaugmented Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890059da-ce0b-46d2-adce-0827047ce039",
   "metadata": {},
   "source": [
    "## Manually Split Data Into Training, Testing, and Validating Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a958ee-a9ee-46a3-b7f7-e38fd0b3fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 63 to training, 14 to testing, 13 to validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab4094-f507-4285-8dbf-dfdeafede039",
   "metadata": {},
   "source": [
    "## Move the Matching Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c730f-abcd-44a5-b598-137ce01ea30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ['train', 'test', 'val']:\n",
    "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
    "        filename = file.split('.')[0]+'.json'\n",
    "        existing_filepath = os.path.join('data', 'labels', filename)\n",
    "        if os.path.exists(existing_filepath):\n",
    "            new_filepath = os.path.join('data', folder, 'labels', filename)\n",
    "            os.replace(existing_filepath, new_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dab216-72a7-4aac-b09f-9974cfb3e36c",
   "metadata": {},
   "source": [
    "# Apply Image Augmentation on Images and Labels using Albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7073147-601c-422b-aca4-aa1b611940d8",
   "metadata": {},
   "source": [
    "## Setup Albumentations Transform Pipeline from Pascal VOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fae40-c574-4f5e-b456-14b5d2101ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde15a5-2343-4d06-8cb3-d14486b2a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450),\n",
    "                         alb.HorizontalFlip(p=0.5),\n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.randomGamma(p=0.2),\n",
    "                         alb.RGBShift(p=0.2),\n",
    "                         alb.VerticalFlip(p=0.5)],\n",
    "                        bbox_params=alb.BboxParams(format='albumentations',\n",
    "                                                   label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90419b00-2955-4621-9b11-eb181ce06495",
   "metadata": {},
   "source": [
    "## Load a Test Image and Annotation with OpenCV and JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb1e22-b445-49e9-b8d7-646e5f48e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join('data', 'train', 'images', '2bfaa34a-3567-11ee-8539-2e397a80a3b0.jpg'))\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1510775-0119-4ec9-a09b-b9b4578cb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'train', 'labels', '2bfaa34a-3567-11ee-8539-2e397a80a3b0.json'), 'r' as f):\n",
    "    label = json.load(f)\n",
    "# label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40086315-1226-46ac-8d7d-4fa73330635d",
   "metadata": {},
   "source": [
    "## Extract Coordinates and Rescale to Match Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7149b-226f-4b17-a591-a2e54d8b96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [0, 0, 0, 0]\n",
    "coords[0] = label['shapes'][0]['points'][0][0]\n",
    "coords[1] = label['shapes'][0]['points'][0][1]\n",
    "coords[2] = label['shapes'][0]['points'][1][0]\n",
    "coords[3] = label['shapes'][0]['points'][1][1]\n",
    "#x1, x2, y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd1170-3865-4786-afed-b107e978828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = list(np.divide(coords, [640, 480, 640, 480]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af989d7-1537-4106-8852-9b38d21b47d8",
   "metadata": {},
   "source": [
    "## Apply Augmentation and View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16574361-8741-4ce2-bf3c-5c5aa6e0f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
    "# augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c61ff-de31-4163-84bd-afa206bd730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(augmented['image'],\n",
    "              tuple(np.multiply(augmented['bboxes'][0][:2], [450,450]).astype(int)),\n",
    "              tuple(np.multiply(augmented['bboxes'][0][2:], [450,450]).astype(int)),\n",
    "              (255,0,0), 2)\n",
    "\n",
    "plt.imshow(augmented['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40615fc-ca7e-4dcd-a43d-360d0541a6d0",
   "metadata": {},
   "source": [
    "# Build and Run Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20076cb-fcf3-453a-bf7c-d089c30b35c5",
   "metadata": {},
   "source": [
    "# Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d3a57-db10-426c-ad4d-4ffcf60c1366",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [640,480,640,480]))\n",
    "\n",
    "        try: \n",
    "            for x in range(60):\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "# creates 60 augmented images per image rendered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5780d-f6c6-4458-b45b-7bff12fca92c",
   "metadata": {},
   "source": [
    "## Load Augmented Images to Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1eed2b-36b6-4233-b41e-5205e2e3dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg', shuffle=False)\n",
    "train_images = train_images.map(load_image)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba45107-91c1-4ab8-9ade-e76cdaa5e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(load_image)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c5ba7-e553-4444-8e17-3d7cdb21c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(load_image)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f10936-301b-4b5e-86eb-ea10cd41194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94fe05d-da61-4951-a234-7e4191bc6c09",
   "metadata": {},
   "source": [
    "# Prepare Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0dbfa-330e-4f24-9166-f7440bc59cb6",
   "metadata": {},
   "source": [
    "## Build Label Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28edec66-2c50-4423-8dc8-472ce255ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding='utf-8 as f:\n",
    "              label = json.load(f)\n",
    "    return [label['class']], label['bbox']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ca793-edc4-459c-9127-d8ae80dad7e6",
   "metadata": {},
   "source": [
    "## Load Labels to Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353a5a8-8bb0-47de-975b-ae9611b40b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7c7e7-9cad-4b2b-b286-fd8827aacbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c632d-f99c-4b10-ae3d-6bde68d90c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_data\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c4c35-a4e8-4c90-aab2-b349930a1e8d",
   "metadata": {},
   "source": [
    "# Combine Label and Image Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa220dd-2f48-48fd-99a2-ba63e353a729",
   "metadata": {},
   "source": [
    "## Check Partition Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8bda9-f8ad-485e-b39f-c421b65d3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_images), len(test_images), len(val_images), len(train_labels), len(test_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb00e25-fe4f-475f-8159-8200673b1b8f",
   "metadata": {},
   "source": [
    "## Create Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80949e91-a3bb-4ea6-86d8-ba56d1981019",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels))\n",
    "train = train.shuffle(5000)\n",
    "train = train.batch(8)\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24eabcc-53d5-4d74-bd87-649248c43b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(5000)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a3d9a-f1ef-4477-945e-71b5680377cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(5000)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)\n",
    "#train.as_numpy_iterator().next()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d815c4eb-06f5-484e-92b8-48f7d0f092fb",
   "metadata": {},
   "source": [
    "## View Images and Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fdea7-0470-44fe-8673-7bf7169187a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45602f-96d0-49b7-ab0f-9f72040a4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data_samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0777c9f-7b1d-4c4d-a46f-d149ec886893",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = res[0][idx]\n",
    "    sample_coords = res[1][1][idx]\n",
    "    \n",
    "    cv2.rectangle(sample_image, \n",
    "                  tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "                  tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "                        (255,0,0), 2)\n",
    "\n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048f69d-8e66-417d-8e40-646a6c9d4f4e",
   "metadata": {},
   "source": [
    "# Build Deep Learning with Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52976c2a-79ad-498c-961e-8dea09729620",
   "metadata": {},
   "source": [
    "## Import Layers and Base Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fddcc48-45c6-4cc1-917a-89fbb7cf0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b135e38-f722-428e-b022-916276d95364",
   "metadata": {},
   "source": [
    "## Download VGG16 and View Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a4610-8bb6-4e6f-a630-a71a57ff6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77271a2a-def8-4fcd-ae0f-fd059af8fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a66c13-0b54-42d5-92b8-d3234fc28ec6",
   "metadata": {},
   "source": [
    "## Build Instance of Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a1f72-5727-4489-8a2b-2f42f9d3a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    input_layer = Input(shape=(120,120,3))\n",
    "    \n",
    "    vgg = VGG16(include_top=False)(input_layer)\n",
    "\n",
    "    # Classification Model  \n",
    "    f1 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(f1)\n",
    "    class2 = Dense(1, activation='sigmoid')(class1)\n",
    "    \n",
    "    # Bounding box model\n",
    "    f2 = GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = Dense(2048, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "    \n",
    "    facetracker = Model(inputs=input_layer, outputs=[class2, regress2])\n",
    "    return facetracker\n",
    "#train.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302593d-c859-41f8-9b84-f30eb1254755",
   "metadata": {},
   "source": [
    "## Test the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70b480-6b54-450b-ad39-e3f9b9469ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetracker = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe6aca-9b54-49eb-add7-407fe0bd949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetracker.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80707e0-ec98-4718-94fd-acbc5783c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d053e-978f-40c1-9603-d2017114bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393eeae8-2593-4525-bfe5-0449a88cc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, coords = facetracker.predict(X)\n",
    "classes, coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9a392-b179-46bb-9458-c5e8858a2de8",
   "metadata": {},
   "source": [
    "# Define Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f380d-e4af-4e7a-abf7-1d8a4b00ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3566e-962c-4031-8e92-6efdf0c96491",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = 690\n",
    "lr_decay = (1./0.75 - 1)/batches_per_epoch\n",
    "#sets the decay rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79779de-8cf4-4d49-a108-bddd6263db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66e6d0-48e7-4b2e-af2f-3dc3627b2fe7",
   "metadata": {},
   "source": [
    "## Create Localization and Classification Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5156464-0fa8-4a0f-b207-a76b00c67528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):            \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2]))\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] \n",
    "    w_true = y_true[:,2] - y_true[:,0] \n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    \n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    \n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cbbb4-e0b9-43ba-9250-bc087b91ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.BinaryCrossentropy()\n",
    "regressloss = localization_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf823b-cc33-4efa-bffd-bf241c056bcb",
   "metadata": {},
   "source": [
    "## Test Loss Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14aa956-399d-4f39-9127-b5ee0c0b641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "localization_loss(y[1], coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82e491-8320-4502-9e0c-dfab6d2bfcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss(y[0], classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849055b-7fd5-4531-8071-e589e5e48c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_loss(y[1], coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb492180-3166-4f4f-9dfb-ad3f738addcc",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b70b33-2ad5-4cd6-ba5a-593ee6a2bdc7",
   "metadata": {},
   "source": [
    "## Create Custom Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d0688-839a-4527-b1af-a887595273a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTracker(Model): \n",
    "    def __init__(self, eyetracker,  **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.model = eyetracker\n",
    "\n",
    "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classloss\n",
    "        self.lloss = localizationloss\n",
    "        self.opt = opt\n",
    "    \n",
    "    def train_step(self, batch, **kwargs): \n",
    "        \n",
    "        X, y = batch\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            classes, coords = self.model(X, training=True)\n",
    "            \n",
    "            batch_classloss = self.closs(y[0], classes)\n",
    "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "            \n",
    "            total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "            \n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        \n",
    "        opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "    \n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        \n",
    "        classes, coords = self.model(X, training=False)\n",
    "        \n",
    "        batch_classloss = self.closs(y[0], classes)\n",
    "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "        total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "        \n",
    "    def call(self, X, **kwargs): \n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62f162-4d80-4f37-925a-b82fdec32996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceTracker(facetracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac154a3-9707-4e25-981a-ebe90660a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, classloss, regressloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a2d9a-b8dc-46fb-8f9e-aa9586c4ca63",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0fb125-583d-464c-94d0-84f258efff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9bc40e-9528-4b9e-9d1c-e0a4d453ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e603499-8ea6-4acb-9855-3463b14c5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=40, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082296c9-f5f0-4dc7-ab40-961abcafa786",
   "metadata": {},
   "source": [
    "## Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3708141-c66b-43e1-a081-dbe393da5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b40af0-250d-4161-bdb6-a0da5ce163ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(20,5))\n",
    "\n",
    "ax[0].plot(hist.history['total_loss'], color='teal', label='loss')\n",
    "ax[0].plot(hist.history['val_total_loss'], color='orange', label='val loss')\n",
    "ax[0].title.set_text('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(hist.history['class_loss'], color='teal', label='class loss')\n",
    "ax[1].plot(hist.history['val_class_loss'], color='orange', label='val class loss')\n",
    "ax[1].title.set_text('Classification Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(hist.history['regress_loss'], color='teal', label='regress loss')\n",
    "ax[2].plot(hist.history['val_regress_loss'], color='orange', label='val regress loss')\n",
    "ax[2].title.set_text('Regression Loss')\n",
    "ax[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa278e-a96b-44ff-9387-d1023ea9a1fa",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45df758-6135-4996-be94-465f40e700e4",
   "metadata": {},
   "source": [
    "## Make Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a79cd6-6d01-439a-80a4-c035a3e357d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf27bad-fad5-428e-a7bf-b50f4765baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3dfb85-6d83-4278-9b9a-9f6d6fcb58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = facetracker.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cfac1b-ee67-447b-a42c-4313ca46e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = test_sample[0][idx]\n",
    "    sample_coords = yhat[1][idx]\n",
    "    \n",
    "    if yhat[0][idx] > 0.9:\n",
    "        cv2.rectangle(sample_image, \n",
    "                      tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234bd29b-189d-4104-95d9-b14fb360205b",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732729a-1283-439f-af02-f45bbaaf1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "while cap.isOpened():\n",
    "    _ , frame = cap.read()\n",
    "    frame = frame[50:500, 50:500,:]\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = tf.image.resize(rgb, (120,120))\n",
    "    \n",
    "    yhat = facetracker.predict(np.expand_dims(resized/255,0))\n",
    "    sample_coords = yhat[1][0]\n",
    "    \n",
    "    if yhat[0] > 0.5: \n",
    "        # Controls the main rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "        # Controls the label rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int), \n",
    "                                    [0,-30])),\n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                    [80,0])), \n",
    "                            (255,0,0), -1)\n",
    "        \n",
    "        # Controls the text rendered\n",
    "        cv2.putText(frame, 'face', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                               [0,-5])),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('EyeTrack', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2513ec-86e2-4224-991c-3e8902cb77e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
